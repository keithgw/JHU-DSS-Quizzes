---
title: "Quiz 3 PML"
author: "Keith G. Williams"
date: "Tuesday, April 14, 2015"
output: html_document
---
## Question 1
Load the cell segmentation data from the AppliedPredictiveModeling package
```{r}
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
```

1. Subset the data to a training set and testing set based on the Case variable in the data set. 
```{r}
library(dplyr)
training <- segmentationOriginal %>% filter(Case == "Train")
testing <- segmentationOriginal %>% filter(Case == "Test")
```

2. Set the seed to 125 and fit a CART model with the rpart method using all predictor variables and default caret settings. 
```{r}
set.seed(125)
modelFit <- train(Class ~ ., method = "rpart", data = training)
```
3. In the final model what would be the final model prediction for cases with the following variable values:
a. TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2 
b. TotalIntench2 = 50,000; FiberWidthCh1 = 10;VarIntenCh4 = 100 
c. TotalIntench2 = 57,000; FiberWidthCh1 = 8;VarIntenCh4 = 100  
d. FiberWidthCh1 = 8;VarIntenCh4 = 100; PerimStatusCh1=2 

```{r, fig.height=8}
plot(modelFit$finalModel, uniform=TRUE, 
     main="Classification Tree")
text(modelFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
```

## Question 2
If K is small in a K-fold cross validation is the bias in the estimate of out-of-sample (test set) accuracy smaller or bigger? If K is small is the variance in the estimate of out-of-sample (test set) accuracy smaller or bigger. Is K large or small in leave one out cross validation?

**Answer:** If K is small, bias is large, and variance is small. LOOCV has the property K == sample size, so K is at its maximum.

## Question 3
Load the olive oil data set
```{r}
library(pgmm)
data(olive)
olive = olive[,-1]
```

These data contain information on 572 different Italian olive oils from multiple regions in Italy. Fit a classification tree where Area is the outcome variable. Then predict the value of area for the following data frame using the tree command with all defaults.
```{r}
library(tree)
treeFit <- tree(Area ~ ., data=olive)
newdata = as.data.frame(t(colMeans(olive)))
predict(treeFit, newdata=newdata)
```

## Question 4
Load the South Africa Heart Disease Data and create training and test sets.
```{r}
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
```

Then set the seed to 13234 and fit a logistic regression model (method="glm", be sure to specify family="binomial") with Coronary Heart Disease (chd) as the outcome and age at onset, current alcohol consumption, obesity levels, cumulative tabacco, type-A behavior, and low density lipoprotein cholesterol as predictors.
```{r}
set.seed(13234)
logFit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
                method = "glm", family = "binomial", data = trainSA)
```

Calculate the misclassification rate for your model using this function and a prediction on the "response" scale:
```{r}
missClass = function(values,prediction){
                sum(((prediction > 0.5)*1) != values)/length(values)
            }
trainPredict <- predict(logFit, newdata = trainSA)
testPredict <- predict(logFit, newdata = testSA)
```

misclassification rate training prediction:
```{r}
missClass(trainSA$chd, trainPredict)
```

misclassification rate testing prediction:
```{r}
missClass(testSA$chd, testPredict)
```

## Question 5
Load the vowel.train and vowel.test data sets:

```{r}
library(ElemStatLearn)
data(vowel.train)
data(vowel.test) # not needed to answer this Q
```

Set the variable y to be a factor variable in both the training and test set. Then set the seed to 33833. Fit a random forest predictor relating the factor variable y to the remaining variables. Read about variable importance in random forests here: [http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#ooberr](http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#ooberr)

```{r, cache=TRUE}
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y) # not needed to answer this Q

set.seed(33833)

rfFit <- train(y ~ ., data=vowel.train, method="rf")
```

The caret package uses by default the Gini importance. Calculate the variable importance using the varImp function in the caret package. What is the order of variable importance?
```{r}
varImp(rfFit)
# 2 1 5 6 8 4 9 3 7 10
```